% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tr_causal.R
\name{get_causal_tokens_log_prob_tbl}
\alias{get_causal_tokens_log_prob_tbl}
\title{Get the log probability of each token in a sentence (or group of sentences) using a causal transformer}
\usage{
get_causal_tokens_log_prob_tbl(
  texts,
  model = "gpt2",
  add_bos_token = NULL,
  stride = 1,
  config_model = NULL,
  config_tokenizer = NULL,
  .id = NULL
)
}
\arguments{
\item{texts}{Vector or list of texts.}

\item{model}{Name of a pretrained model stored on the huggingface.co. (Maybe a path to a  model (.pt or .bin file) stored locally will work.)}

\item{add_bos_token}{Whether to include beginning of text special tokens. By default  acts as the \href{https://huggingface.co/docs/transformers/v4.25.1/en/model_doc/auto#transformers.AutoTokenizer}{AutoTokenizer}.}

\item{config_model}{List with other arguments that control how the model from hugging face is accessed.}

\item{config_tokenizer}{List with arguments that control how the tokenizer from hugging face is accessed.}

\item{.id}{Column with sentence id.}
}
\value{
A table with token names, log-probability and optionally sentence id.
}
\description{
Get the log probability of each token in a sentence (or group of sentences) using a causal transformer model. See \code{vignette("transformer-gpt2", package = "pangoling")} for examples.
}
\details{
For more about causal models, see (https://huggingface.co/course/chapter7/6).  Using the  \code{config_model} and \code{config_tokenizer} arguments, it's possible to control how the model and tokenizer from hugging face is accessed, see \href{https://huggingface.co/docs/transformers/v4.25.1/en/model_doc/auto#transformers.AutoProcessor.from_pretrained}{from_pretrained} for details. In case of errors check the status of https://status.huggingface.co/
}
