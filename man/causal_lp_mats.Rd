% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tr_causal.R
\name{causal_lp_mats}
\alias{causal_lp_mats}
\title{Get a list of matrices with the log probabilities of possible word given its previous context using a causal transformer}
\usage{
causal_lp_mats(
  x,
  .by = rep(1, length(x)),
  model = getOption("pangoling.causal.default"),
  add_special_tokens = NULL,
  config_model = NULL,
  config_tokenizer = NULL
)
}
\arguments{
\item{x}{Vector of words, phrases or texts.}

\item{.by}{Vector that indicates how the text should be split.}

\item{model}{Name of a pretrained model stored locally on the (huggingface.co).}

\item{add_special_tokens}{Whether to include beginning of text special tokens. By default  acts as the \href{https://huggingface.co/docs/transformers/v4.25.1/en/model_doc/auto#transformers.AutoTokenizer}{AutoTokenizer}.}

\item{config_model}{List with other arguments that control how the model from hugging face is accessed.}

\item{config_tokenizer}{List with other arguments that control how the tokenizer from hugging face is accessed.}

\item{ignore_regex}{Can ignore certain characters when calculates the log probabilities. For example \verb{^[[:punct:]]$} will ignore all punctuation  that stands alone in a token.}
}
\value{
A list of matrices with tokens in their columns and the vocabulary of the model in their rows
}
\description{
Get a list of matrices with the log probabilities of possible word given its previous context using a causal transformer model.
}
\details{
For more about causal models, see \href{https://huggingface.co/course/chapter7/6}{chapter 7 of hugging face documentation}.

If not specified, the causal model that will be used is the one set in specified in the global option \code{pangoling.causal.default}, this can be accessed via \code{getOption("pangoling.causal.default")} (by default "gpt2"). To change the default option use \code{options(pangoling.causal.default = "newcausalmodel")}.

A list of possible causal models can be found in \href{https://huggingface.co/}{hugging face website}.

Using the  \code{config_model} and \code{config_tokenizer} arguments, it's possible to control how the model and tokenizer from hugging face is accessed, see the python method \href{https://huggingface.co/docs/transformers/v4.25.1/en/model_doc/auto#transformers.AutoProcessor.from_pretrained}{\code{from_pretrained}} for details. In case of errors check the status of \url{https://status.huggingface.co/}
}
\section{More examples}{

See the  \href{https://bruno.nicenboim.me/pangoling/articles/intro-gpt2.html}{online article} in pangoling website for more examples.
}

\examples{
\dontshow{if (interactive()) (if (getRversion() >= "3.4") withAutoprint else force)(\{ # examplesIf}
causal_lp_mats(
  x = c("The", "apple", "doesn't", "fall", "far", "from", "the", "tree."),
  model = "gpt2"
)
\dontshow{\}) # examplesIf}
}
\seealso{
Other causal model functions: 
\code{\link{causal_config}()},
\code{\link{causal_lp}()},
\code{\link{causal_next_tokens_tbl}()},
\code{\link{causal_preload}()},
\code{\link{causal_tokens_lp_tbl}()}
}
\concept{causal model functions}
