% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tr_causal.R
\name{get_causal_next_tokens_tbl}
\alias{get_causal_next_tokens_tbl}
\title{Get the possible next tokens and their log probabilities its previous context using a causal transformer}
\usage{
get_causal_next_tokens_tbl(
  context,
  model = "gpt2",
  add_bos_token = NULL,
  config_model = NULL,
  config_tokenizer = NULL
)
}
\arguments{
\item{context}{Context.}

\item{model}{Name of a pretrained model stored on the huggingface.co. (Maybe a path to a  model (.pt or .bin file) stored locally will work.)}

\item{add_bos_token}{Whether to include beginning of text special tokens. By default  acts as the \href{https://huggingface.co/docs/transformers/v4.25.1/en/model_doc/auto#transformers.AutoTokenizer}{AutoTokenizer}.}

\item{config_model}{List with other arguments that control how the model from hugging face is accessed.}

\item{config_tokenizer}{List with arguments that control how the tokenizer from hugging face is accessed.}
}
\value{
A table with possible next tokens and their log-probabilities.
}
\description{
Get the possible next tokens and their log probabilities its previous context using a causal transformer model from \href{https://huggingface.co}{Hugging Face}.  Get the log probability of each word phrase of a vector given its previous context using a transformer model from huggingface.co/. See \code{vignette("transformer-gpt2", package = "pangoling")} for examples.
}
\details{
For more about causal models, see (https://huggingface.co/course/chapter7/6). Using the  \code{config_model} and \code{config_tokenizer} arguments, it's possible to control how the model and tokenizer from hugging face is accessed, see \href{https://huggingface.co/docs/transformers/v4.25.1/en/model_doc/auto#transformers.AutoProcessor.from_pretrained}{from_pretrained} for details. In case of errors check the status of https://status.huggingface.co/
}
